{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI 机器人强化学习从入门到提高 **(草稿)**\n",
    "\n",
    "> 除了试图直接去建立一个可以模拟成人大脑的程序之外， 为什么不试图建立一个可以模拟小孩大脑的程序呢?如果它接 受适当的教育，就会获得成人的大脑。 — 阿兰·图灵\n",
    "\n",
    "## 学习目的\n",
    "\n",
    "- 理论和仿真实践结合\n",
    "- 了解掌握强化学习基本原理\n",
    "- 掌握利用 Python 进行强化学习仿真\n",
    "\n",
    "## 一. 引言介绍\n",
    "\n",
    "强化学习 (Reinforcement learning) 是机器学习的一个子领域用于制定决策和运动自由度控制。强化学习主要研究在复杂未知的环境中，智体(agent)实现某个目标。强化学习最引人入胜的两个特点是\n",
    "\n",
    "- **强化学习非常通用，可以用来解决需要作出一些列决策的所有问题：**例如，训练机器人跑步和弹跳，制定商品价格和库存管理，玩 Atari 游戏和棋盘游戏等等。\n",
    "\n",
    "- **强化学习已经可以在许多复杂的环境中取得较好的实验结果：**例如 Deep RL 的 Alpha Go等\n",
    "\n",
    "[Gym](https://gym.openai.com/docs/) 是一个研究和开发强化学习相关算法的仿真平台。\n",
    "\n",
    "- 无需智体先验知识；\n",
    "- 兼容常见的数值运算库如 TensorFlow、Theano 等\n",
    "\n",
    "## 二. 强化学习的基本概念\n",
    "\n",
    "强化学习也是机器学习中的一个重要分支。强化学习和监督学习的不同在 于，强化学习问题不需要给出“正确”策略作为监督信息，只需要给出策略的(延迟)回报，并通过调整策略来取得最大化的期望回报。\n",
    "\n",
    "![](https://ws1.sinaimg.cn/large/c3a916a7gy1fuipsc9dnrj20iy05g74p.jpg)\n",
    "\n",
    "### 2.1 术语\n",
    "\n",
    "- 智体 (Agent): 执行动作对环境产生影响，感知外接环境状态(state)和反馈奖励(reward)，并进行学习和决策。\n",
    "- 环境 (Environment)： 出了智体以外的所有事物，智体动作可以影响环境状态，反馈智体奖励。\n",
    "- 状态 $s$ (State)：是环境的描述。\n",
    "- 动作 $a$ (Action)：对智体行为的描述。\n",
    "- 策略 $\\pi$ (Policy)：智体根据环境的状态来决定下一步动作$a$的函数。\n",
    "- 奖励 $r$ (Reward)：当智体完成动作之后，环境会响应的给智体一个奖励(标量值)$r$。\n",
    "- 状态转移概率 ：智体从前一个状态完成动作后，环境在下个时间点转变成状态s的概率\n",
    "\n",
    "### 2.2 马尔科夫过决策过程\n",
    "\n",
    "#### 原理图\n",
    "\n",
    "\n",
    "\n",
    "![](https://ws1.sinaimg.cn/large/c3a916a7gy1fujcxmkef7j20kp04vaa7.jpg)\n",
    "\n",
    "#### 解释\n",
    "\n",
    "- 智能体与环境的交互的过程可以看作是一个**马尔可夫决策过程**。马尔可夫过程(Markov process)是具有马尔可夫性的随机变量序列$s_0,s_1,...,s_t$ 下一个时刻的状态 $s_{t+1}$ 只取决于当前时刻的 $s_{t}$ \n",
    "\n",
    "$$p\\left(s_{t+1} \\mid s_t,...,s_0 \\right) = p\\left(s_{t+1} \\mid s_{t}\\right)$$\n",
    "\n",
    "- 给定策略$\\pi\\left(a\\mid s\\right)$，轨迹\n",
    "\n",
    "$$\\tau = s_0,a_0,s_1,r_1,a_1,...,s_{T-1},s_T,r_T$$\n",
    "\n",
    "### 强化学习优化的目标函数\n",
    "\n",
    "- 总回报，折扣率 $\\gamma \\in \\left[0,1\\right]$\n",
    "\n",
    "$$G_{T}=\\sum_{t=0}^{T-1}\\gamma ^{t} r_{t+1}$$\n",
    "\n",
    "- 目标函数\n",
    "\n",
    "$$J\\left( \\theta \\right) = E\\left[G\\left(\\tau \\right)\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三. OpenAI 强化学习仿真环境\n",
    "\n",
    "- A standard Python API for RL environments\n",
    "- A set of tools to measure agent performance\n",
    "- An online scoreboard for comparing and benchmarking approaches\n",
    "- [ https://gym.openai.com/](https://gym.openai.com/)\n",
    "\n",
    "### 3.1 环境安装\n",
    "\n",
    "- pip 安装  \n",
    "    ```\n",
    "    pip3 install gym\n",
    "    ```\n",
    "- 源码安装  \n",
    "    ```shell\n",
    "    git clone https://github.com/openai/gym.git\n",
    "    cd gym\n",
    "    pip install -e .\n",
    "    ```\n",
    "- 验证安装是否成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of input instance: 3, step: 0\n",
      "==========================================\n",
      "Observation Tape    :   \u001b[42mD\u001b[0mBC  \n",
      "Output Tape         :   \n",
      "Targets             :   DBC  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x1043684e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('Copy-v0')\n",
    "env.reset()\n",
    "env.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 OpenAI 术语解释\n",
    "\n",
    "- **观测** Observation (Object)：当前 step 执行后，环境的观测(类型为对象)。例如，从相机获取的像素点，机器人各个关节的角度或棋盘游戏当前的状态等；\n",
    "\n",
    "- **奖励** Reward (Float): 执行上一步动作(action)后，智体(agent)获得的奖励(浮点类型)，不同的环境中奖励值变化范围也不相同，但是强化学习的目标就是使得总奖励值最大；\n",
    "\n",
    "- **完成** Done (Boolen): 表示是否需要将环境重置 `env.reset`。大多数情况下，当 `Done` 为 `True` 时，就表明当前回合(episode)或者试验(tial)结束。例如当机器人摔倒或者掉出台面，就应当终止当前回合进行重置(reset);\n",
    "\n",
    "- **信息** Info (Dict): 针对调试过程的诊断信息。在标准的智体仿真评估当中不会使用到这个 info，具体用到的时候再说。\n",
    "\n",
    "![](https://ws1.sinaimg.cn/large/c3a916a7gy1fui6vljemkj20gw066t93.jpg)\n",
    "\n",
    "总结来说，这就是一个强化学习的基本流程，在每个时间点上，智体执行 action，环境返回上一次 action 的观测和奖励，用图表示为"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四. 第一个强化学习 Hello World\n",
    "\n",
    "### 车杆模型\n",
    "\n",
    "![](https://ws1.sinaimg.cn/large/c3a916a7gy1fuilrzjnj0j20hm0blmxu.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "init state =  [ 0.03829178 -0.01427857 -0.00701367  0.00567602]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "init_state = env.reset()\n",
    "print('init state = ', init_state)\n",
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action) # take a random action\n",
    "    if done: \n",
    "        env.render()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 概念解读\n",
    "\n",
    "- 创建实例\n",
    "    - 每个 Gym 环境都有唯一的命名，命名方式为 `([A-Za-z0-9]+-)v([0-9]+)`\n",
    "    - 使用 `gym.make('CartPole-v0')` 创建环境\n",
    "\n",
    "- 重置函数 reset\n",
    "    - 用于重新开启一个新的回合(试验)\n",
    "    - 返回回合的初始状态\n",
    "\n",
    "- 执行(step)\n",
    "    - 执行特定的动作，返回状态(state)\n",
    "    - observation, reward, done, info\n",
    "    \n",
    "- 渲染(render)\n",
    "    - 用于显示当前环境的状态\n",
    "    - 用于调试和定性的分析不同策略的效果\n",
    "\n",
    "### 空间(space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Discrete(2)\n",
      "Box(4,)\n",
      "[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "print(env.action_space)\n",
    "#> Discrete(2)\n",
    "print(env.observation_space)\n",
    "#> Box(4,)\n",
    "\n",
    "print(env.observation_space.high)\n",
    "print(env.observation_space.low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 观测空间 `observation_space` 是一个 `Box` 类型，从 [box.py](https://github.com/openai/gym/blob/master/gym/spaces/box.py) 源码可知，表示一个 `n` 维的盒子，所以在上一节打印出来的 `observation` 是一个长度为 4 的数组。数组中的每个元素都具有上下界。\n",
    "\n",
    "    - Type: Box(4)\n",
    "\n",
    "Num | Observation | Min | Max\n",
    "---|---|---|---\n",
    "0 | Cart Position | -2.4 | 2.4\n",
    "1 | Cart Velocity | -Inf | Inf\n",
    "2 | Pole Angle | ~ -41.8&deg; | ~ 41.8&deg;\n",
    "3 | Pole Velocity At Tip | -Inf | Inf\n",
    "\n",
    "- 运动空间 `action_space` 是一个离散 `Discrete` 类型，从 [discrete.py](https://github.com/openai/gym/blob/master/gym/spaces/discrete.py) 源码可知，范围是一个 `{0,1,...,n-1}` 长度为 `n` 的非负整数集合，在 `CartPole-v0` 例子中，动作空间表示为 `{0,1}`。\n",
    "\n",
    "    - Type: Discrete(2)\n",
    "\n",
    "Num | Action\n",
    "--- | ---\n",
    "0 | Push cart to the left\n",
    "1 | Push cart to the right\n",
    "\n",
    "\n",
    "### 回合终止条件(当满足下列条件之一时，终止回合)\n",
    "\n",
    "- 1. 杆的角度超过 $\\pm12$ 度\n",
    "- 2. 以中点为原点，小车位置超过 $\\pm24$ \n",
    "- 3. 回合长度超过 200 次\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 求解 Cartpole 杆车模型\n",
    "\n",
    "#### 求解算法\n",
    "\n",
    "- The random guessing algorithm: generate 10,000 random configurations of the model's parameters, and pick the one that achieves the best cumulative reward. It is important to choose the distribution over the parameters correctly.\n",
    "- The hill-climbing algorithm: Start with a random setting of the parameters, add a small amount of noise to the parameters, and evaluate the new parameter configuration. If it performs better than the old configuration, discard the old configuration and accept the new one. Repeat this process for some number of iterations. How long does it take to achieve perfect performance?\n",
    "- Policy gradient algorithm: here, instead of choosing the action as a deterministic function of the sign of the weighted sum, make it so that action is chosen randomly, but where the distribution over actions (of which there are two) depends on the numerical output of the inner product. Policy gradient prescribes a principled parameter update rule [1, 2]. Your goal is to implement this algorithm for the simple linear model, and see how long it takes to converge.\n",
    "\n",
    "#### 算法步骤\n",
    "\n",
    "- 定义策略 Policy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 代码求解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "observation space: Box(4,)\n",
      "action space: Discrete(2)\n",
      "Episode 100\tAverage Score: 175.24\n",
      "Environment solved in 13 episodes!\tAverage Score: 196.21\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "print('observation space:', env.observation_space)\n",
    "print('action space:', env.action_space)\n",
    "env.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Define policy\n",
    "class Policy():\n",
    "    def __init__(self, s_size=4, a_size=2):\n",
    "        self.w = 1e-4*np.random.rand(s_size, a_size)  # weights for simple linear policy: state_space x action_space\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = np.dot(state, self.w)\n",
    "        return np.exp(x)/sum(np.exp(x))\n",
    "    \n",
    "    def act(self, state):\n",
    "        probs = self.forward(state)\n",
    "        #action = np.random.choice(2, p=probs) # option 1: stochastic policy\n",
    "        action = np.argmax(probs)              # option 2: deterministic policy\n",
    "        return action\n",
    "\n",
    "    \n",
    "policy = Policy()\n",
    "    \n",
    "def hill_climbing(n_episodes=1000, max_t=1000, gamma=1.0, print_every=100, noise_scale=1e-2):\n",
    "    \"\"\"Implementation of hill climbing with adaptive noise scaling.\n",
    "        \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        gamma (float): discount rate\n",
    "        print_every (int): how often to print average score (over last 100 episodes)\n",
    "        noise_scale (float): standard deviation of additive noise\n",
    "    \"\"\"\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    best_R = -np.Inf\n",
    "    best_w = policy.w\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        rewards = []\n",
    "        state = env.reset()\n",
    "        for t in range(max_t):\n",
    "            action = policy.act(state)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            rewards.append(reward)\n",
    "            if done:\n",
    "                break \n",
    "        scores_deque.append(sum(rewards))\n",
    "        scores.append(sum(rewards))\n",
    "\n",
    "        discounts = [gamma**i for i in range(len(rewards)+1)]\n",
    "        R = sum([a*b for a,b in zip(discounts, rewards)])\n",
    "\n",
    "        if R >= best_R: # found better weights\n",
    "            best_R = R\n",
    "            best_w = policy.w\n",
    "            noise_scale = max(1e-3, noise_scale / 2)\n",
    "            policy.w += noise_scale * np.random.rand(*policy.w.shape) \n",
    "        else: # did not find better weights\n",
    "            noise_scale = min(2, noise_scale * 2)\n",
    "            policy.w = best_w + noise_scale * np.random.rand(*policy.w.shape)\n",
    "\n",
    "        if i_episode % print_every == 0:\n",
    "            print('Episode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "        if np.mean(scores_deque)>=195.0:\n",
    "            print('Environment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_deque)))\n",
    "            policy.w = best_w\n",
    "            break\n",
    "        \n",
    "    return scores\n",
    "            \n",
    "scores = hill_climbing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 绘制分数 reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "state = env.reset()\n",
    "for t in range(200):\n",
    "    action = policy.act(state)\n",
    "    env.render()\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    if done:\n",
    "        break \n",
    "\n",
    "env.close()\n",
    "print('env.close()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五. OpenAI 强化学习进阶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello reinforcement learning !\n",
      "Hello reinforcement learning !\n",
      "Hello reinforcement learning !\n",
      "Hello reinforcement learning !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Hello reinforcement learning !\\n'*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六. 总结与扩展"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 项目地址\n",
    "- 扩展阅读文献 1\n",
    "- 扩展阅读文献 2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
