{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI 机器人强化学习的快速入门 **(草稿)**\n",
    "\n",
    "> 除了试图直接去建立一个可以模拟成人大脑的程序之外， 为什么不试图建立一个可以模拟小孩大脑的程序呢?如果它接 受适当的教育，就会获得成人的大脑。 — 阿兰·图灵\n",
    "\n",
    "## 学习目的\n",
    "\n",
    "- 理论和仿真实践结合\n",
    "- 了解掌握强化学习基本原理\n",
    "- 掌握利用 Python 进行强化学习仿真\n",
    "\n",
    "## 一. 引言介绍\n",
    "\n",
    "强化学习 (Reinforcement learning) 是机器学习的一个子领域用于制定决策和运动自由度控制。强化学习主要研究在复杂未知的环境中，智体(agent)实现某个目标。强化学习最引人入胜的两个特点是\n",
    "\n",
    "- **强化学习非常通用，可以用来解决需要作出一些列决策的所有问题：**例如，训练机器人跑步和弹跳，制定商品价格和库存管理，玩 Atari 游戏和棋盘游戏等等。\n",
    "\n",
    "- **强化学习已经可以在许多复杂的环境中取得较好的实验结果：**例如 Deep RL 的 Alpha Go等\n",
    "\n",
    "[Gym](https://gym.openai.com/docs/) 是一个研究和开发强化学习相关算法的仿真平台。\n",
    "\n",
    "- 无需智体先验知识；\n",
    "- 兼容常见的数值运算库如 TensorFlow、Theano 等\n",
    "\n",
    "## 二. 强化学习的基本概念\n",
    "\n",
    "强化学习也是机器学习中的一个重要分支。强化学习和监督学习的不同在 于，强化学习问题不需要给出“正确”策略作为监督信息，只需要给出策略的(延迟)回报，并通过调整策略来取得最大化的期望回报。\n",
    "\n",
    "### 2.1 术语\n",
    "\n",
    "- 智体 (Agent)\n",
    "- 环境 (Environment)\n",
    "- 状态 (State)\n",
    "- 动作 (Action)\n",
    "- 策略 (Policy)\n",
    "- 奖励 (Reward)\n",
    "- 状态转移概率 \n",
    "\n",
    "### 2.2 马尔科夫过决策过程\n",
    "\n",
    "- 图片\n",
    "- 解释\n",
    "\n",
    "## 三. OpenAI 强化学习仿真环境\n",
    "\n",
    "### 3.1 环境安装\n",
    "\n",
    "- step1\n",
    "- step2\n",
    "- step3\n",
    "\n",
    "### 3.2 OpenAI 术语解释\n",
    "\n",
    "- Observations\n",
    "- Spaces\n",
    "- Loop\n",
    "- Render\n",
    "\n",
    "## 四. 第一个强化学习 Hello World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello reinforcement learning !\n",
      "Hello reinforcement learning !\n",
      "Hello reinforcement learning !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Hello reinforcement learning !\\n'*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五. OpenAI 强化学习进阶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello reinforcement learning !\n",
      "Hello reinforcement learning !\n",
      "Hello reinforcement learning !\n",
      "Hello reinforcement learning !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Hello reinforcement learning !\\n'*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六. 总结与扩展"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 项目地址\n",
    "- 扩展阅读文献 1\n",
    "- 扩展阅读文献 2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
